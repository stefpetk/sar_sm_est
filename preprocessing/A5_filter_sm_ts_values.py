import pandas as pd
import numpy as np
import glob
import os
import shutil


class filt_mean_ismn_files:
    """
    Class with functions which take the last character of the folders where the S1 GRD images as well as the soil
    moisture and temperature .csv are stored, the path of the GRD images as well as the soil moisture and temperature,
    the name of the soil moisture and temperature measuring instrument and then filter the soil moisture and
    temperature .csv files according to the acquisition date times of the S1 GRD images.

    """

    def __init__(self, folds_path, folder_ending, GRD_ims_path, csv_files_path, to_avg_list, to_avg_vals, im_or_list,
                 backscatter_list_path):
        """

        Args:
            folds_path: a string which contains the path to the folders where ISMN data is stored (ex. C:/FR_Aqui/*)
            downloaded in the Header+values format

            folder_ending: a list of strings which contains the "index" number at the end of each ISMN station and GRD
            image associated folder or folder containing timeseries with the mean value of a backscatter coefficient
            (ex. for the folders associated with the station A_1, B_2 and C_3 we get the list ['1', '2', '3']

            im_or_list: a string which indicates if a set of S1 GRD images will be used for the filtering of the ISMN
            data or a list with the mean values of the backscatter coefficient (gamma0) for each station

            GRD_ims_path: the path to the folder where the associated GRD images for each station are stored
            (ex. 'C:/GRD_Images/*_{}/*.tif')

            csv_files_path: the path to the folder where the ISMN .csv data files are located
            (ex. 'C:/ISMN_Station/*_{}/*.csv')

            backscatter_list_path: the path to the .csv files for each station where the S1 backscatter coefficient
            timeseries are stored (ex. 'C:/Backscatter_Timeseries/*_{}/*.csv')

            to_avg_list: a list which contains lists with dataframes (the returning object of the filt_ismn_files
            function) for which the user wants to compute the average value of the soil moisture, soil temperature etc

            to_avg_vals: a string which indicates the header of the variable of the dataframes which will be averaged and
            can be one of the following --> 'SM_(%)': soil moisture, 'S_Temp_(Celsius)': soil temperature,
            'Air_Temp_(Celsius)': air temperature, 'Precip_(mm)': precipitation

        """
        self.folds_path = folds_path
        self.folder_ending = folder_ending
        self.im_or_list = im_or_list
        self.backscatter_list_path = backscatter_list_path
        self.GRD_ims_path = GRD_ims_path
        self.csv_files_path = csv_files_path
        self.to_avg_list = to_avg_list
        self.to_avg_vals = to_avg_vals

    def filt_ismn_files(self):
        """

        Returns: upd_station_dfs --> a list of dataframes where the soil moisture and temeprature measurements for
        each ISMN station are

        """

        assert self.im_or_list in ['GRD Images', 'Backscatter Coefficient Timeseries']

        station_grd_fnames = []
        station_tseries_dates_times = []
        station_fnames = []
        station_ims_dates = []
        station_ims_times = []

        for n in self.folder_ending:
            station_fnames.append(glob.glob(self.csv_files_path.format(n)))
            if self.im_or_list == 'GRD Images':
                station_grd_fnames.append(
                    [os.path.basename(grd_im) for grd_im in glob.glob(self.GRD_ims_path.format(n))])
            else:
                station_tseries_dates_times.append(pd.read_csv(glob.glob(self.backscatter_list_path.format(n))[0],
                                                               usecols=['C0/date', 'C0/time']))
        # generation of a list (station_grd_fnames) which contains as many S1 GRD image filename lists #
        # (generated by the glob.glob() function) as folders containing images or a list which contains the dates #
        # of the backscatter coefficient timeseries (station_tseries_dates) for each station and finally a list #
        # (station_fnames) which stores the ISMN data csv files in sublists according to the number of stations #

        if self.im_or_list == 'GRD Images':
            for i in range(len(station_grd_fnames)):
                station_ims_dates.append([])
                station_ims_times.append([])
                for j in range(len(station_grd_fnames[i])):
                    station_ims_dates[i].append(station_grd_fnames[i][j][:8])
                    station_ims_times[i].append(station_grd_fnames[i][j].split('T', 1)[1][:5])
        else:
            for i in range(len(station_tseries_dates_times)):
                station_ims_dates.append(station_tseries_dates_times[i]['C0/date'].to_list())
                station_ims_times.append(station_tseries_dates_times[i]['C0/time'].to_list())

        for i in range(len(station_ims_dates)):
            for j in range(len(station_ims_dates[i])):
                if self.im_or_list == 'GRD Images':
                    station_ims_dates[i][j] = station_ims_dates[i][j][:4] + '/' + station_ims_dates[i][j][4:6] + '/' + \
                                              station_ims_dates[i][j][6:8]
                    station_ims_times[i][j] = station_ims_times[i][j][:2] + ':' + station_ims_times[i][j][2:4]
                else:
                    station_ims_dates[i][j] = station_ims_dates[i][j][:4] + '/' + station_ims_dates[i][j][5:7] + '/' + \
                                              station_ims_dates[i][j][8:10]
        # generation of two lists (station_ims_dates and station_ims_times) which contain the acquisition
        # dates and times of the S1 GRD images in the format YYYY/MM/DD for the dates and HH/MM for the
        # timestamps

        upd_station_ims_times = []
        station_dfs = []
        upd_station_dfs = []

        for g in range(len(station_fnames)):
            station_dfs.append([])
            for h in range(len(station_fnames[g])):
                station_dfs[g].append(
                    pd.read_csv(station_fnames[g][h], sep=' ', on_bad_lines='skip', dtype=object))
                # creation of a list which contains the csv files for each station inserted into the script as
                # dataframes #

        for i in range(len(station_ims_times)):
            upd_station_ims_times.append([])
            for j in range(len(station_ims_times[i])):
                if int(station_ims_times[i][j][3:5]) < 30 and int(station_ims_times[i][j][0:2]) < 23:
                    upd_station_ims_times[i].append(station_ims_times[i][j][:3] + '00')
                elif int(station_ims_times[i][j][3:5]) > 30 and 10 < int(station_ims_times[i][j][0:2]) < 23:
                    upd_station_ims_times[i].append(str(1 + int(station_ims_times[i][j][0:2])) + ':00')
                elif int(station_ims_times[i][j][3:5]) > 30 and 0 < int(station_ims_times[i][j][1:2]) < 9:
                    upd_station_ims_times[i].append('0' + str(1 + int(station_ims_times[i][j][1:2])) + ':00')
                else:
                    upd_station_ims_times.append('00:00')
                    # filtering of the time values in the station_ims_times list so that they match the time values in
                    # the stations soil moisture and temperature acquisition times #

        for j in range(len(station_dfs)):
            upd_station_dfs.append([])
            for k in range(len(station_dfs[j])):
                upd_station_dfs[j].append(station_dfs[j][k][station_dfs[j][k]['Date'].
                                          isin(station_ims_dates[j])])
                upd_station_dfs[j][k] = upd_station_dfs[j][k][upd_station_dfs[j][k]['Time'].
                    isin(upd_station_ims_times[j])]
                upd_station_dfs[j][k].drop_duplicates(subset='Date', inplace=True)
            # filtering of the dataframes generated by the soil moisture and temperature .csv files so that the 'Date'
            # and 'Time' columns contain values that are associated with the acquisition dates and times of the S1 GRD
            # images for each station #

        return upd_station_dfs

    def filt_ismn_qf(self):
        """
        This functionality filters soil moisture, soil temperature etc. values in the corresponding dataframes that are
        flagged as faulty (for example negative soil moisture values or peaks in the soil moisture time series that can
        not be explained by a rain event)

        Returns: a dataframe

        """

        filt_qf_dfs = filt_mean_ismn_files.filt_ismn_files(self)
        sm_date_range = []

        for i in range(len(filt_qf_dfs)):
            sm_date_range.append(None)
            for j in range(len(filt_qf_dfs[i])):
                filt_qf_dfs[i][j] = filt_qf_dfs[i][j].loc[filt_qf_dfs[i][j]['Quality_Flag_1']. \
                    str.contains('G|D01|D02|D03|D01,D02|D01,D03|D02,D03|D01,DO2,D03', regex=True)]
                if filt_qf_dfs[i][j].columns[2] == 'SM_(m^3/m^3)':
                    filt_qf_dfs[i][j]['Below_Freezing_Temp'] = filt_qf_dfs[i][j]['Quality_Flag_1']. \
                        str.contains('D01|D02|D03|D01,D02|D01,D03|D02,D03|D01,DO2,D03', regex=True)
                    sm_date_range[i] = filt_qf_dfs[i][j]['Date'].to_list()
                else:
                    pass

        for i in range(len(filt_qf_dfs)):
            for j in range(len(filt_qf_dfs[i])):
                filt_qf_dfs[i][j] = filt_qf_dfs[i][j][filt_qf_dfs[i][j]['Date'].isin(sm_date_range[i])]

        return filt_qf_dfs

    def comp_mean(self):
        """
        This functionality computes the mean value of the soil moisture or temperature for each date for the ISMN
        station that are very close to each other
        """
        ismn_dfs_lists = self.to_avg_list
        # first enter a list with all the filenames of the csv files that are associated with either the soil
        # moisture or temperature for the stations for which the user wants to compute the mean value for 2 or more
        # dataframes

        ismn_series_list = []
        for i in range(len(ismn_dfs_lists)):
            ismn_series_list.append([])
            for j in range(len(ismn_dfs_lists[i])):
                ismn_series_list[i].append(ismn_dfs_lists[i][j][ismn_dfs_lists[i][j].columns[2]])
                ismn_series_list[i][j] = (ismn_series_list[i][j].reset_index(drop=True)).astype('float')
                # append the columns of the dataframes which only contain data series of interest (soil moisture, soil
                # temperature etc.)

        ismn_np_arrs = []
        for i in range(len(ismn_series_list)):
            ismn_np_arrs.append(pd.concat(ismn_series_list[i], axis=1, ignore_index=True).to_numpy())
            # concatenate the pandas series of interest and turn the list of series to a numpy array

        ismn_mean_vect = []
        for i in range(len(ismn_np_arrs)):
            ismn_mean_vect.append(np.zeros((len(ismn_np_arrs[i][:])), ))
            for j in range(len(ismn_mean_vect[i])):
                ismn_mean_vect[i][j] = np.mean(ismn_np_arrs[i][j][:])
                # compute the mean value for each row of the numpy array

        for i in range(len(self.to_avg_vals)):
            assert self.to_avg_vals[i] in ['SM_(%)', 'S_Temp_(Celsius)', 'Air_Temp_(Celsius)', 'Precip_(mm)']
            # assert that the ISMN data columns in the final dataframes will have as headers the above strings

        final_df_list = []
        for i, j in zip(range(len(ismn_mean_vect)), range(len(self.to_avg_vals))):
            ismn_mean_list = ismn_mean_vect[i].tolist()
            final_df_list.append(pd.DataFrame(data=ismn_mean_list, columns=[self.to_avg_vals[j]]))
            final_df_list[i] = pd.concat([ismn_dfs_lists[i][0]['Date'].reset_index(drop=True),
                                          ismn_dfs_lists[i][0]['Time'].reset_index(drop=True),
                                          final_df_list[i].reset_index(drop=True),
                                          ismn_dfs_lists[i][0]['Quality_Flag_1'].reset_index(drop=True),
                                          ismn_dfs_lists[i][0]['Quality_Flag_2'].reset_index(drop=True)],
                                         axis=1)
            # create a new list of dataframes with a column where the mean value of
            # separate ISMN data columns is stored for each date, time, quality flag etc.

        return final_df_list

    def cr_filt_dir(self):
        """
        This functionalty creates a new parent folder of the type 'XXX_STATIONS_FILT' (depends on the ISMN data folders path
        given) and also copies the folders contained in the parent folder as well as the static variables .xlsx file
        contatined in each station folder
        """
        in_stats_folds = self.folds_path[:-2]
        filt_stats_folds = in_stats_folds[:-2] + 'FILT'
        if not os.path.isdir(filt_stats_folds):
            os.mkdir(filt_stats_folds)
        else:
            pass
        # create a new parent folder for the stations for which the filtered dataframes are going to be stored

        for (path, dirs, files) in os.walk(in_stats_folds):
            for dir in dirs:
                stat_folds_dir = filt_stats_folds + '/' + dir
                if dir != [] and not os.path.isdir(stat_folds_dir):
                    os.mkdir(stat_folds_dir)
                else:
                    pass
                    # create folders within the parent folder where the filtered data for each station are going to be
                    # stored

        st_vars_sourcepth = in_stats_folds + '/*_{}/*.xlsx'
        for end in self.folder_ending:
            shutil.copy2(glob.glob(st_vars_sourcepth.format(end))[0],
                         filt_stats_folds + '/' + glob.glob(st_vars_sourcepth.format(end))[0].
                         split('\\', 1)[1])

        st_vars_destpath = filt_stats_folds + '/*_{}/*.xlsx'

        for end in self.folder_ending:
            os.replace(filt_stats_folds + '/' + glob.glob(st_vars_destpath.format(end))[0].split('\\', 1)[1],
                       filt_stats_folds + '/' +
                       glob.glob(st_vars_destpath.format(end))[0].split('\\', 1)[1][:-5] + '.csv')

            # copy the static variables .xlsx file for each station and then change the file extension back to .csv (as
            # this file can only be accessed and manipulated with the .csv format)
